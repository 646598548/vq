{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1893859/2213283413.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/layers0_q_centroids.pt').to(dev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 448, 1792])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1893859/2213283413.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  index=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_indices.pt').to(dev)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dev=torch.device('cpu')\n",
    "centroids=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/vptq_qwen2-7/model.layers.0.self_attn.q_proj_centroids.pt').to(dev)\n",
    "index=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_indices.pt').to(dev)\n",
    "print(index.shape)\n",
    "centroids=centroids.weight.view(1,65536,8)\n",
    "# high_mask=0xffff0000\n",
    "# low_mask=0x0000ffff\n",
    "# new_index=torch.zeros([448,3584]).to(dev).to(torch.int32).to(dev)\n",
    "# for j in range(index.shape[1]):\n",
    "#     for k in range(index.shape[2]):\n",
    "#         packint32=index[0,j,k].to(torch.int32)\n",
    "#         new_index[j,2*k+1]=torch.bitwise_right_shift(packint32.to(torch.int64),16).to(torch.uint16)\n",
    "#         new_index[j,2*k]=torch.bitwise_and(packint32, 0xFFFF).to(torch.uint16)\n",
    "#矢量化加速\n",
    "# centroids = centroids.weight.view(1, 65536, 8)\n",
    "high_mask = 0xffff0000  # 未使用，可保留或删除\n",
    "low_mask = 0x0000ffff   # 未使用，可保留或删除\n",
    "new_index = torch.zeros([448, 3584], dtype=torch.int32, device=dev)\n",
    "\n",
    "# 矢量化操作\n",
    "lower = index[0] & 0xFFFF              # 提取低16位，形状 (448, 1792)\n",
    "upper = (index[0] >> 16) & 0xFFFF      # 提取高16位，形状 (448, 1792)\n",
    "new_index = torch.stack([lower, upper], dim=2).view(448, 3584)  # 重组为 (448, 3584)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0425,  0.0938,  0.3320,  ...,  0.3301, -1.1328,  0.2773],\n",
      "        [-1.2422,  0.0864, -0.7734,  ..., -0.7617,  0.5703,  0.6680],\n",
      "        [-0.5898, -0.5234,  0.9375,  ...,  0.5547,  0.1206, -1.3125],\n",
      "        ...,\n",
      "        [-0.3516, -0.2197, -0.7109,  ..., -0.3730, -0.7539, -1.0156],\n",
      "        [ 0.0184,  0.0171,  0.1187,  ...,  0.6602, -0.2695, -1.1719],\n",
      "        [ 0.0171, -0.4277, -0.8867,  ...,  1.0156,  0.2383, -0.5039]],\n",
      "       grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "centroids = centroids.view(65536, 8).to(dev)  # 修正拼写错误并准备张量\n",
    "recon_weight = torch.zeros([448, 3584], device=dev)\n",
    "assert new_index.min() >= 0 and new_index.max() < 65536, \"new_index 包含越界索引\"\n",
    "# 使用矢量化操作替代嵌套循环\n",
    "recon_weight = centroids[new_index, 0]\n",
    "\n",
    "print(recon_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3047,  0.2969,  0.0869, -0.6758],\n",
      "        [-1.5859, -0.3848, -0.5078,  0.6797],\n",
      "        [ 0.3398,  0.5508,  0.2969,  0.7734],\n",
      "        ...,\n",
      "        [-0.6758,  1.3359,  1.9375,  0.6289],\n",
      "        [-0.5391, -1.8281, -0.0403,  0.1484],\n",
      "        [-1.6719,  1.6875,  0.3750, -1.1406]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "centroids = centroids.view(16384, 32).to(device=dev, dtype=torch.float32)\n",
    "# 创建 code 张量，确保在 dev 上并为 float32\n",
    "code = torch.zeros([16384, 4], dtype=torch.float32, device=dev)\n",
    "code = centroids[:, [0, 8, 16, 24]]\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "yx=new_index.cpu().detach()\n",
    "y=yx[0,0:50]\n",
    "x=range(50)\n",
    "plt.figure(figsize=(20, 12))  # 设置图形大小\n",
    "plt.scatter(x, y, label='y = sin(x)', color='b')  # 绘制折线图\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('1D Data Plot', fontsize=16)\n",
    "plt.xlabel('X-axis', fontsize=30)\n",
    "plt.ylabel('Y-axis', fontsize=12)\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 添加网格线\n",
    "plt.grid(True)\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_hit(index=torch.Tensor,cache_size=None,dev=None):\n",
    "    index_pool=torch.zeros([cache_size],dtype=torch.int32).cpu()\n",
    "    allindex=index.shape[0]*index.shape[1]\n",
    "    hit=0\n",
    "    a=int(cache_size/2-1)\n",
    "    index=index.cpu()\n",
    "    for i in range(index.shape[0]):\n",
    "        for j in range(index.shape[1]):\n",
    "            if torch.eq(index_pool, index[i][j]).any() :\n",
    "                hit=hit+1\n",
    "            else:\n",
    "                if index[i][j]<=a:\n",
    "                    index_pool=torch.arange(0,cache_size)\n",
    "                else:\n",
    "                    index_pool[0:a]=torch.arange(index[i][j]-a,index[i][j])\n",
    "                    index_pool[a+1:cache_size-1]=torch.arange(index[i][j],index[i][j]+a)#缺少一个右边界条件\n",
    "\n",
    "    return hit,hit/allindex\n",
    "print(cache_hit(new_index,500,dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.Tensor([[1,0,1],\n",
    "                [1,1,1]])\n",
    "a=a.t()\n",
    "print(torch.nonzero(a!=1)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class cache_sim:\n",
    "    def __init__(self, mode, linesize, cachesize, num_lin, codebook):\n",
    "        self.mode = mode\n",
    "        self.linesize = linesize  # 这里的linesize表示能装几个code\n",
    "        self.cachesize = cachesize\n",
    "        self.num_lin = num_lin\n",
    "        # self.uesd_record = torch.ones([self.num_lin]) * -1  # 第一列表示是否为空，第二列表示最近使用时间.\n",
    "        self.cache = torch.ones([self.num_lin, self.linesize]) * -1\n",
    "        self.time = 0\n",
    "        self.codebook = codebook\n",
    "        self.l = []  # 记录使用\n",
    "\n",
    "    def maintain_record(self, used_line_num):\n",
    "        # print(used_line_num)\n",
    "        if used_line_num in self.l:\n",
    "            self.l.remove(used_line_num) # 如果出现在self l中 那么都会被删除 然后将其补至最后  确保LRU替换策略\n",
    "            self.l.append(used_line_num)\n",
    "        else:\n",
    "            self.l.append(used_line_num)\n",
    "\n",
    "    def is_empty(self):\n",
    "        if len(self.l) < self.num_lin:\n",
    "            return -1\n",
    "        else:\n",
    "            return self.l.pop(0)  # 弹出最早使用的序号\n",
    "\n",
    "    def load_data(self, data):\n",
    "        indices = self.is_empty()\n",
    "        # print(self.codebook,data)\n",
    "        in_code = torch.nonzero(self.codebook == data)[0, 0].item()\n",
    "        # print(indices)\n",
    "        if indices != -1:\n",
    "            # print(indices)\n",
    "            # print(self.cache.shape,self.codebook.shape)\n",
    "            self.cache[indices] = self.codebook[in_code]\n",
    "            self.maintain_record(indices)\n",
    "        else:\n",
    "            for x in range(self.num_lin):\n",
    "                if x in self.l:\n",
    "                    continue\n",
    "                else:\n",
    "                    self.cache[x] = self.codebook[in_code]\n",
    "                    self.maintain_record(x)\n",
    "                    break\n",
    "\n",
    "    def sim(self, read_data):\n",
    "        indices = torch.nonzero(self.cache == read_data) \n",
    "        if torch.numel(indices) == 0:\n",
    "            indices=indices\n",
    "            self.load_data(read_data)\n",
    "            return False\n",
    "        else:\n",
    "            indices = indices[0]\n",
    "            self.maintain_record(indices[0])\n",
    "            return True\n",
    "\n",
    "cache = cache_sim(mode=None, linesize=4, cachesize=None, num_lin=256, codebook=code)\n",
    "sum_cnt=0\n",
    "hit_cnt=0\n",
    "for i in range(448):\n",
    "        for k in range(3584):\n",
    "            sum_cnt=sum_cnt+1\n",
    "            if cache.sim(recon_weight[i,k])==True:\n",
    "                hit_cnt=hit_cnt+1\n",
    "            else:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.6140\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "class cache_sim:\n",
    "    def __init__(self, mode, linesize, cachesize, num_lin, codebook):\n",
    "        self.linesize = linesize\n",
    "        self.num_lin = num_lin\n",
    "        self.cache = torch.full((num_lin, linesize), -1)\n",
    "        self.codebook = codebook\n",
    "        \n",
    "        # 预建 codebook 值到行的快速映射 (值 -> 行索引)\n",
    "        self.codebook_value_map = {}\n",
    "        for row_idx, row in enumerate(codebook):\n",
    "            for val in row:\n",
    "                val = val.item()\n",
    "                if val not in self.codebook_value_map:\n",
    "                    self.codebook_value_map[val] = row_idx\n",
    "        \n",
    "        # 使用 OrderedDict 实现高效 LRU 机制\n",
    "        self.lru = OrderedDict()\n",
    "        \n",
    "        # 值到缓存行的反向映射 (值 -> 所在行集合)\n",
    "        self.value_to_lines = defaultdict(set)\n",
    "        # 缓存行到值的反向映射 (行 -> 存储的值集合)\n",
    "        self.line_to_values = [set() for _ in range(num_lin)]\n",
    "\n",
    "    def maintain_record(self, line):\n",
    "        \"\"\" 更新 LRU 记录，O(1) 时间复杂度 \"\"\"\n",
    "        if line in self.lru:\n",
    "            self.lru.move_to_end(line)\n",
    "        else:\n",
    "            self.lru[line] = None\n",
    "\n",
    "    def is_empty(self):\n",
    "        \"\"\" 返回可替换的行或 -1 \"\"\"\n",
    "        if len(self.lru) < self.num_lin:\n",
    "            return -1\n",
    "        else:\n",
    "            # 弹出 LRU 行并清理其反向映射\n",
    "            lru_line, _ = self.lru.popitem(last=False)\n",
    "            for val in self.line_to_values[lru_line]:\n",
    "                self.value_to_lines[val].remove(lru_line)\n",
    "                if not self.value_to_lines[val]:\n",
    "                    del self.value_to_lines[val]\n",
    "            self.line_to_values[lru_line].clear()\n",
    "            return lru_line\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\" 加载数据到缓存，向量化操作 \"\"\"\n",
    "        data_val = data.item()\n",
    "        if data_val not in self.codebook_value_map:\n",
    "            raise ValueError(f\"Value {data_val} not in codebook\")\n",
    "        \n",
    "        code_row = self.codebook[self.codebook_value_map[data_val]]\n",
    "        target_line = self.is_empty()\n",
    "        \n",
    "        if target_line == -1:\n",
    "            # 寻找未使用的行\n",
    "            for line in range(self.num_lin):\n",
    "                if line not in self.lru:\n",
    "                    target_line = line\n",
    "                    break\n",
    "            # 如果所有行已使用，触发 LRU 替换\n",
    "            if target_line == -1:\n",
    "                target_line = self.is_empty()\n",
    "        # print(target_line)\n",
    "        # 更新缓存行数据\n",
    "        self.cache[target_line] = code_row\n",
    "        # 更新反向映射\n",
    "        new_values = set(code_row.tolist())\n",
    "        for val in new_values:\n",
    "            self.value_to_lines[val].add(target_line)\n",
    "        self.line_to_values[target_line] = new_values\n",
    "        self.maintain_record(target_line)\n",
    "\n",
    "    def sim(self, read_data):\n",
    "        \"\"\" 批量查询优化，O(1) 时间复杂度 \"\"\"\n",
    "        data_val = read_data.item()\n",
    "        \n",
    "        # \n",
    "        if data_val in self.value_to_lines:\n",
    "            # 取第一个关联行并更新 LRU\n",
    "            line = next(iter(self.value_to_lines[data_val]))\n",
    "            self.maintain_record(line)\n",
    "            return True\n",
    "        else:\n",
    "            self.load_data(read_data)\n",
    "            # print('not hit')\n",
    "            return False\n",
    "\n",
    "\n",
    "# 测试循环优化\n",
    "def run_simulation(cache, recon_weight):\n",
    "    # 将输入数据转换为向量化操作\n",
    "    recon_flatten = recon_weight.view(-1)\n",
    "    hit_cnt = torch.sum(torch.tensor([\n",
    "        cache.sim(val) for val in recon_flatten\n",
    "    ], dtype=torch.int32))\n",
    "    return hit_cnt.item(), len(recon_flatten)\n",
    "\n",
    "# 初始化\n",
    "cache = cache_sim(mode=None, linesize=4, cachesize=None, num_lin=256, codebook=code)\n",
    "hit_cnt, sum_cnt = run_simulation(cache, recon_weight)\n",
    "print(f\"Hit Rate: {hit_cnt / sum_cnt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIFO Hit Rate: 0.5980\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "class cache_sim_fifo:\n",
    "    def __init__(self, mode, linesize, cachesize, num_lin, codebook):\n",
    "        self.linesize = linesize\n",
    "        self.num_lin = num_lin\n",
    "        self.cache = torch.full((num_lin, linesize), -1)\n",
    "        self.codebook = codebook\n",
    "        \n",
    "        # 预建 codebook 值到行的快速映射 (值 -> 行索引)\n",
    "        self.codebook_value_map = {}\n",
    "        for row_idx, row in enumerate(codebook):\n",
    "            for val in row:\n",
    "                val = val.item()\n",
    "                if val not in self.codebook_value_map:\n",
    "                    self.codebook_value_map[val] = row_idx\n",
    "        \n",
    "        # FIFO 队列 (核心改动)\n",
    "        self.fifo_queue = deque(maxlen=num_lin)  # 自动淘汰最早进入的项\n",
    "        \n",
    "        # 值到缓存行的反向映射 (值 -> 所在行集合)\n",
    "        self.value_to_lines = defaultdict(set)\n",
    "        # 缓存行到值的反向映射 (行 -> 存储的值集合)\n",
    "        self.line_to_values = [set() for _ in range(num_lin)]\n",
    "\n",
    "    def maintain_record(self, line):\n",
    "        \"\"\" FIFO 只在加载时记录新行，不调整顺序 (核心改动) \"\"\"\n",
    "        if line not in self.fifo_queue:\n",
    "            self.fifo_queue.append(line)\n",
    "\n",
    "    def is_empty(self):\n",
    "        \"\"\" 返回可替换的行或 -1 \"\"\"\n",
    "        if len(self.fifo_queue) < self.num_lin:\n",
    "            return -1\n",
    "        else:\n",
    "            # 弹出 FIFO 队列最旧的行 (核心改动)\n",
    "            lru_line = self.fifo_queue.popleft()\n",
    "            # 清理反向映射\n",
    "            for val in self.line_to_values[lru_line]:\n",
    "                self.value_to_lines[val].remove(lru_line)\n",
    "                if not self.value_to_lines[val]:\n",
    "                    del self.value_to_lines[val]\n",
    "            self.line_to_values[lru_line].clear()\n",
    "            return lru_line\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\" 加载数据到缓存 \"\"\"\n",
    "        data_val = data.item()\n",
    "        if data_val not in self.codebook_value_map:\n",
    "            raise ValueError(f\"Value {data_val} not in codebook\")\n",
    "        \n",
    "        code_row = self.codebook[self.codebook_value_map[data_val]]\n",
    "        target_line = self.is_empty()\n",
    "        \n",
    "        if target_line == -1:\n",
    "            # 寻找未使用的行 (新逻辑)\n",
    "            for line in range(self.num_lin):\n",
    "                if line not in self.fifo_queue:\n",
    "                    target_line = line\n",
    "                    break\n",
    "            # 如果所有行已使用，触发 FIFO 替换\n",
    "            if target_line == -1:\n",
    "                target_line = self.is_empty()\n",
    "\n",
    "        # 更新缓存行数据\n",
    "        self.cache[target_line] = code_row\n",
    "        # 更新反向映射\n",
    "        new_values = set(code_row.tolist())\n",
    "        for val in new_values:\n",
    "            self.value_to_lines[val].add(target_line)\n",
    "        self.line_to_values[target_line] = new_values\n",
    "        self.maintain_record(target_line)  # 仅在此处更新队列\n",
    "\n",
    "    def sim(self, read_data):\n",
    "        \"\"\" 查询优化 (命中时不更新队列顺序) \"\"\"\n",
    "        data_val = read_data.item()\n",
    "        if data_val in self.value_to_lines:\n",
    "            # FIFO 不更新访问顺序 (核心改动)\n",
    "            return True\n",
    "        else:\n",
    "            self.load_data(read_data)\n",
    "            return False\n",
    "\n",
    "# 使用示例\n",
    "cache_fifo = cache_sim_fifo(\n",
    "    mode=None, linesize=4, cachesize=None, \n",
    "    num_lin=256, codebook=code\n",
    ")\n",
    "\n",
    "# 测试方法与之前相同\n",
    "def run_simulation(cache, recon_weight):\n",
    "    recon_flatten = recon_weight.view(-1)\n",
    "    hit_cnt = torch.sum(torch.tensor([\n",
    "        cache.sim(val) for val in recon_flatten\n",
    "    ], dtype=torch.int32))\n",
    "    return hit_cnt.item(), len(recon_flatten)\n",
    "\n",
    "hit_cnt, sum_cnt = run_simulation(cache_fifo, recon_weight)\n",
    "print(f\"FIFO Hit Rate: {hit_cnt / sum_cnt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cache_sim_set_associative_fifo:\n",
    "    def __init__(self, mode, linesize, cachesize, num_lin, codebook, associativity=4):\n",
    "        # 参数校验\n",
    "        assert num_lin % associativity == 0, \"Cache lines must be divisible by associativity\"\n",
    "        assert associativity >= 1, \"Associativity must be at least 1\"\n",
    "        \n",
    "        # 基础参数\n",
    "        self.linesize = linesize\n",
    "        self.num_lin = num_lin\n",
    "        self.associativity = associativity\n",
    "        self.groups = num_lin // associativity  # 计算组数\n",
    "        self.cache = torch.full((num_lin, linesize), -1)\n",
    "        self.codebook = codebook\n",
    "\n",
    "        # 预建codebook值到行的映射\n",
    "        self.codebook_value_map = {}\n",
    "        for row_idx, row in enumerate(codebook):\n",
    "            for val in row:\n",
    "                val = val.item()\n",
    "                if val not in self.codebook_value_map:\n",
    "                    self.codebook_value_map[val] = row_idx\n",
    "\n",
    "        # 为每个组维护FIFO队列\n",
    "        self.group_queues = [deque(maxlen=associativity) for _ in range(self.groups)]\n",
    "\n",
    "        # 反向映射数据结构\n",
    "        self.value_to_lines = defaultdict(set)\n",
    "        self.line_to_values = [set() for _ in range(num_lin)]\n",
    "\n",
    "    def _get_replacement_line(self, group):\n",
    "        \"\"\" 在指定组中获取需要替换的缓存行 \"\"\"\n",
    "        # 计算组内起始行号\n",
    "        start = group * self.associativity\n",
    "        # 优先寻找空闲行\n",
    "        for line_offset in range(self.associativity):\n",
    "            current_line = start + line_offset\n",
    "            if current_line not in self.group_queues[group]:\n",
    "                return current_line\n",
    "\n",
    "        # 执行FIFO替换\n",
    "        victim = self.group_queues[group].popleft()\n",
    "        \n",
    "        # 清理反向映射\n",
    "        for val in self.line_to_values[victim]:\n",
    "            self.value_to_lines[val].remove(victim)\n",
    "            if not self.value_to_lines[val]:\n",
    "                del self.value_to_lines[val]\n",
    "        self.line_to_values[victim].clear()\n",
    "        \n",
    "        return victim\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\" 加载数据到缓存 \"\"\"\n",
    "        data_val = data.item()\n",
    "        if data_val not in self.codebook_value_map:\n",
    "            raise ValueError(f\"Value {data_val} not in codebook\")\n",
    "\n",
    "        # 获取对应的codebook行和组号\n",
    "        code_row_idx = self.codebook_value_map[data_val]\n",
    "        code_row = self.codebook[code_row_idx]\n",
    "        group = code_row_idx % self.groups  # 关键组映射逻辑\n",
    "\n",
    "        # 获取目标缓存行\n",
    "        target_line = self._get_replacement_line(group)\n",
    "\n",
    "        # 更新缓存内容\n",
    "        self.cache[target_line] = code_row\n",
    "\n",
    "        # 维护组队列\n",
    "        self.group_queues[group].append(target_line)\n",
    "\n",
    "        # 更新反向映射\n",
    "        new_values = set(code_row.tolist())\n",
    "        self.line_to_values[target_line] = new_values\n",
    "        for val in new_values:\n",
    "            self.value_to_lines[val].add(target_line)\n",
    "\n",
    "    def sim(self, read_data):\n",
    "        \"\"\" 模拟缓存访问 \"\"\"\n",
    "        data_val = read_data.item()\n",
    "        if data_val in self.value_to_lines:\n",
    "            return True  # 命中不更新队列\n",
    "        else:\n",
    "            self.load_data(read_data)\n",
    "            return False\n",
    "        \n",
    "cache_fifo = cache_sim_set_associative_fifo(\n",
    "    mode=None, linesize=4, cachesize=None, \n",
    "    num_lin=256, codebook=code,\n",
    "    associativity=8\n",
    ")\n",
    "\n",
    "# 测试方法与之前相同\n",
    "def run_simulation(cache, recon_weight):\n",
    "    recon_flatten = recon_weight.view(-1)\n",
    "    hit_cnt = torch.sum(torch.tensor([\n",
    "        cache.sim(val) for val in recon_flatten\n",
    "    ], dtype=torch.int32))\n",
    "    return hit_cnt.item(), len(recon_flatten)\n",
    "\n",
    "hit_cnt, sum_cnt = run_simulation(cache_fifo, recon_weight)\n",
    "print(f\"FIFO Hit Rate: {hit_cnt / sum_cnt:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
