{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 448, 1792])\n",
      "torch.Size([448, 3584])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3499129/2134733029.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_centroids.pt').to(dev)\n",
      "/tmp/ipykernel_3499129/2134733029.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  index=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_indices.pt').to(dev)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict, defaultdict\n",
    "from collections import deque, defaultdict\n",
    "dev=torch.device('cpu')\n",
    "centroids=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_centroids.pt').to(dev)\n",
    "index=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_indices.pt').to(dev)\n",
    "print(index.shape)\n",
    "centroids=centroids.weight.view(1,65536,8)\n",
    "high_mask = 0xffff0000  # 未使用，可保留或删除\n",
    "low_mask = 0x0000ffff   # 未使用，可保留或删除\n",
    "new_index = torch.zeros([448, 3584], dtype=torch.int32, device=dev)\n",
    "lower = index[0] & 0xFFFF              # 提取低16位，形状 (448, 1792)\n",
    "upper = (index[0] >> 16) & 0xFFFF      # 提取高16位，形状 (448, 1792)\n",
    "new_index = torch.stack([lower, upper], dim=2).view(448, 3584)  # 重组为 (448, 3584)\n",
    "centroids = centroids.view(65536, 8).to(dev)  # 修正拼写错误并准备张量\n",
    "recon_weight = torch.zeros([448, 3584], device=dev)\n",
    "assert new_index.min() >= 0 and new_index.max() < 65536, \"new_index 包含越界索引\"\n",
    "# 使用矢量化操作替代嵌套循环\n",
    "recon_weight = centroids[new_index, 0]\n",
    "print(recon_weight.shape)\n",
    "centroids = centroids.view(16384, 32).to(device=dev, dtype=torch.float32)\n",
    "# 创建 code 张量，确保在 dev 上并为 float32\n",
    "code = torch.zeros([16384, 4], dtype=torch.float32, device=dev)\n",
    "code = centroids[:, [0, 8, 16, 24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_tensor(tensor,subrows,subcoloums):\n",
    "#     # 获取张量的形状\n",
    "#     height, width = tensor.shape\n",
    "    \n",
    "#     # 计算可以分割的块数\n",
    "#     num_blocks_height = height // subrows\n",
    "#     num_blocks_width = width // subcoloums\n",
    "    \n",
    "#     # 定义一个函数来处理每个块\n",
    "#     def process_block(block):\n",
    "#         # 获取块的形状\n",
    "#         block_height, block_width = block.shape\n",
    "#         # 创建一个 16x16 的张量，填充 -1\n",
    "#         padded_block = torch.full((subrows, subcoloums), -1, dtype=block.dtype)\n",
    "#         # 将原始块复制到填充的张量中\n",
    "#         padded_block[:block_height, :block_width] = block\n",
    "#         return padded_block\n",
    "    \n",
    "#     # 创建一个空列表来存储分割后的块\n",
    "#     split_blocks = []\n",
    "    \n",
    "#     # 遍历每个块\n",
    "#     for i in range(num_blocks_height ):\n",
    "#         for j in range(num_blocks_width ):\n",
    "#             # 计算块的起始和结束索引\n",
    "#             start_row = i * subrows\n",
    "#             end_row = (i + 1) * subrows\n",
    "#             start_col = j * subcoloums\n",
    "#             end_col = (j + 1) * subcoloums\n",
    "            \n",
    "#             # 获取块\n",
    "#             block = tensor[start_row:end_row, start_col:end_col]\n",
    "            \n",
    "#             # 处理块并添加到列表中\n",
    "#             split_blocks.append(process_block(block))\n",
    "    \n",
    "#     return split_blocks\n",
    "# split_blocks = split_tensor(new_index,2,16)\n",
    "\n",
    "# # 打印分割后的块数量\n",
    "# print(f\"Number of split blocks: {len(split_blocks)}\")\n",
    "\n",
    "# # 打印第一个块的形状\n",
    "# print(f\"Shape of first block: {split_blocks[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE:\n",
    "    def __init__(self, read_ready,index,subrows,subcoloums,spad):\n",
    "        self.read_ready=read_ready\n",
    "        self.index=index\n",
    "        self.subrows=subrows\n",
    "        self.subcoloums=subcoloums\n",
    "        self.rowlast=None\n",
    "        self.last=None\n",
    "        self.cycle=None\n",
    "        self.spad=spad\n",
    "    def split_tensor(self):\n",
    "    # 获取张量的形状\n",
    "        height, width = self.index.shape\n",
    "        # 计算可以分割的块数\n",
    "        num_blocks_height = height // self.subrows\n",
    "        num_blocks_width = width // self.subcoloums\n",
    "        self.rowlast=num_blocks_height\n",
    "        self.last=num_blocks_width\n",
    "        # 定义一个函数来处理每个块\n",
    "        def process_block(block):\n",
    "            # 获取块的形状\n",
    "            block_height, block_width = block.shape\n",
    "            # 创建一个 16x16 的张量，填充 -1\n",
    "            padded_block = torch.full(( self.subrows, self.subcoloums), -1, dtype=block.dtype)\n",
    "            # 将原始块复制到填充的张量中\n",
    "            padded_block[:block_height, :block_width] = block\n",
    "            return padded_block\n",
    "        # 创建一个空列表来存储分割后的块\n",
    "        split_blocks = []\n",
    "        # 遍历每个块\n",
    "        for i in range(num_blocks_height ):\n",
    "            for j in range(num_blocks_width ):\n",
    "                # 计算块的起始和结束索引\n",
    "                start_row = i *  self.subrows\n",
    "                end_row = (i + 1) *  self.subrows\n",
    "                start_col = j * self.subcoloums\n",
    "                end_col = (j + 1) * self.subcoloums\n",
    "                # 获取块\n",
    "                block = self.index[start_row:end_row, start_col:end_col]\n",
    "                # 处理块并添加到列表中\n",
    "                split_blocks.append(process_block(block))\n",
    "        return split_blocks\n",
    "    \n",
    "    def calculate (self):\n",
    "        split_blocks=self.split_tensor()\n",
    "        print(1)\n",
    "        cycle=0\n",
    "        not_finsh=1\n",
    "        i=0\n",
    "        j=0\n",
    "        while(i!=len(split_blocks)) :\n",
    "            sub_block=split_blocks[i]\n",
    "            load_cycle=torch.sum(torch.tensor([\n",
    "                self.spad.load(val) for val in sub_block.flatten()\n",
    "            ], dtype=torch.int32))\n",
    "            if i % self.rowlast==0 :\n",
    "                comput_cycle=32\n",
    "            else:\n",
    "                comput_cycle=16\n",
    "            print(load_cycle)\n",
    "            i=i+1\n",
    "        return cycle\n",
    "       \n",
    "         # for i in range(len(split_blocks)):\n",
    "\n",
    "        #     if i % self.rowlast==0 :\n",
    "\n",
    "        #     #检查是否边界\n",
    "        #     else : \n",
    "        #         if  self.read_ready==1:  #检查数据是否有效\n",
    "\n",
    "        #         else:\n",
    "          \n",
    "        #     #计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cache_sim:\n",
    "    def __init__(self, mode, linesize, cachesize, num_lin, codebook):\n",
    "        self.linesize = linesize\n",
    "        self.num_lin = num_lin\n",
    "        self.cache = torch.full((num_lin, linesize), -1)\n",
    "        self.codebook = codebook\n",
    "        \n",
    "        # 预建 codebook 值到行的快速映射 (值 -> 行索引)\n",
    "        self.codebook_value_map = {}\n",
    "        for row_idx, row in enumerate(codebook):\n",
    "            for val in row:\n",
    "                val = val.item()\n",
    "                if val not in self.codebook_value_map:\n",
    "                    self.codebook_value_map[val] = row_idx\n",
    "        \n",
    "        # 使用 OrderedDict 实现高效 LRU 机制\n",
    "        self.lru = OrderedDict()\n",
    "        \n",
    "        # 值到缓存行的反向映射 (值 -> 所在行集合)\n",
    "        self.value_to_lines = defaultdict(set)\n",
    "        # 缓存行到值的反向映射 (行 -> 存储的值集合)\n",
    "        self.line_to_values = [set() for _ in range(num_lin)]\n",
    "\n",
    "    def maintain_record(self, line):\n",
    "        \"\"\" 更新 LRU 记录，O(1) 时间复杂度 \"\"\"\n",
    "        if line in self.lru:\n",
    "            self.lru.move_to_end(line)\n",
    "        else:\n",
    "            self.lru[line] = None\n",
    "\n",
    "    def is_empty(self):\n",
    "        \"\"\" 返回可替换的行或 -1 \"\"\"\n",
    "        if len(self.lru) < self.num_lin:\n",
    "            return -1\n",
    "        else:\n",
    "            # 弹出 LRU 行并清理其反向映射\n",
    "            lru_line, _ = self.lru.popitem(last=False)\n",
    "            for val in self.line_to_values[lru_line]:\n",
    "                self.value_to_lines[val].remove(lru_line)\n",
    "                if not self.value_to_lines[val]:\n",
    "                    del self.value_to_lines[val]\n",
    "            self.line_to_values[lru_line].clear()\n",
    "            return lru_line\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\" 加载数据到缓存，向量化操作 \"\"\"\n",
    "        data_val = data.item()\n",
    "        if data_val not in self.codebook_value_map:\n",
    "            raise ValueError(f\"Value {data_val} not in codebook\")\n",
    "        \n",
    "        code_row = self.codebook[self.codebook_value_map[data_val]]\n",
    "        target_line = self.is_empty()\n",
    "        \n",
    "        if target_line == -1:\n",
    "            # 寻找未使用的行\n",
    "            for line in range(self.num_lin):\n",
    "                if line not in self.lru:\n",
    "                    target_line = line\n",
    "                    break\n",
    "            # 如果所有行已使用，触发 LRU 替换\n",
    "            if target_line == -1:\n",
    "                target_line = self.is_empty()\n",
    "        # print(target_line)\n",
    "        # 更新缓存行数据\n",
    "        self.cache[target_line] = code_row\n",
    "        # 更新反向映射\n",
    "        new_values = set(code_row.tolist())\n",
    "        for val in new_values:\n",
    "            self.value_to_lines[val].add(target_line)\n",
    "        self.line_to_values[target_line] = new_values\n",
    "        self.maintain_record(target_line)\n",
    "\n",
    "    def sim(self, read_data):\n",
    "        \"\"\" 批量查询优化，O(1) 时间复杂度 \"\"\"\n",
    "        data_val = read_data.item()\n",
    "        \n",
    "        # \n",
    "        if data_val in self.value_to_lines:\n",
    "            # 取第一个关联行并更新 LRU\n",
    "            line = next(iter(self.value_to_lines[data_val]))\n",
    "            self.maintain_record(line)\n",
    "            return True\n",
    "        else:\n",
    "            self.load_data(read_data)\n",
    "            # print('not hit')\n",
    "            return False\n",
    "        \n",
    "class spad:\n",
    "    def __init__(self, num_bank,num_rows,l1cache,l2cache,code):\n",
    "       self.numbank=num_bank\n",
    "       self.numrows=num_rows\n",
    "       self.rowsize=2*16 #一个row存储16个数据 每个数据2B\n",
    "       self.realtime_numrow=0\n",
    "       self.cache1=l1cache\n",
    "       self.cache2=l2cache\n",
    "       self.l1hit=0\n",
    "       self.l2hit=0\n",
    "    def check(self):\n",
    "        if self.realtime_numrow>1:\n",
    "            self.realtime_numrow=self.realtime_numrow-2\n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "    def load(self,index):\n",
    "        l1=self.cache1.sim(index)\n",
    "        l2=self.cache2.sim(index)\n",
    "        self.realtime_numrow=self.realtime_numrow+1 \n",
    "        if l1==True:\n",
    "            self.l1hit=self.l1hit+1\n",
    "            return 2\n",
    "        elif l1==False and l2==True:\n",
    "            self.l2hit=self.l2hit+1\n",
    "            return 10\n",
    "        elif l1==False and l2 ==False:\n",
    "            return 40\n",
    "        else :\n",
    "            return False\n",
    "    def show_hit(self):\n",
    "        print(\"l1_hit:\",self.l1hit)\n",
    "        print(\"l2_hit:\",self.l2hit)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache1=cache_sim(mode=None, linesize=4, cachesize=None, num_lin=256, codebook=code)\n",
    "cache2=cache_sim(mode=None, linesize=4, cachesize=None, num_lin=1024, codebook=code)\n",
    "sim_spad=spad(4,256,cache1,cache2,None)\n",
    "sim_pe=PE(None,recon_weight,2,16,sim_spad)\n",
    "print(sim_pe.calculate())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
