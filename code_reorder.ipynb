{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1605063/2397418420.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_centroids.pt').to(dev)\n",
      "/tmp/ipykernel_1605063/2397418420.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  index=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_indices.pt').to(dev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 448, 1792])\n",
      "tensor([-0.1514,  0.2871,  0.1934, -0.9297, -0.4824, -1.0703, -0.1309, -0.1436],\n",
      "       dtype=torch.float16, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dev=torch.device('cpu')\n",
    "centroids=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_centroids.pt').to(dev)\n",
    "index=torch.load('/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_indices.pt').to(dev)\n",
    "print(index.shape)\n",
    "centroids=centroids.weight.view(1,65536,8)\n",
    "high_mask = 0xffff0000  # 未使用，可保留或删除\n",
    "low_mask = 0x0000ffff   # 未使用，可保留或删除\n",
    "new_index = torch.zeros([448, 3584], dtype=torch.int32, device=dev)\n",
    "lower = index[0] & 0xFFFF              # 提取低16位，形状 (448, 1792)\n",
    "upper = (index[0] >> 16) & 0xFFFF      # 提取高16位，形状 (448, 1792)\n",
    "new_index = torch.stack([lower, upper], dim=2).view(448, 3584)  # 重组为 (448, 3584)\n",
    "centroids = centroids.view(65536, 8).to(dev)  # 修正拼写错误并准备张量\n",
    "print(centroids[52581])\n",
    "recon_weight = torch.zeros([448, 3584], device=dev)\n",
    "assert new_index.min() >= 0 and new_index.max() < 65536, \"new_index 包含越界索引\"\n",
    "# 使用矢量化操作替代嵌套循环\n",
    "recon_weight = centroids[new_index, 0]\n",
    "centroids = centroids.view(16384, 32).to(device=dev, dtype=torch.float32)\n",
    "# 创建 code 张量，确保在 dev 上并为 float32\n",
    "code = torch.zeros([16384, 4], dtype=torch.float32, device=dev)\n",
    "code = centroids[:, [0, 8, 16, 24]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#特征提取法\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "entry_character=torch.zeros([65536,448])\n",
    "cindex=new_index.cpu()\n",
    "for i in range(new_index.shape[0]):\n",
    "    counts = torch.bincount(cindex[i, :], minlength=entry_character.shape[0])\n",
    "    entry_character[:,i]=counts\n",
    "# print(entry_character)\n",
    "    # print(counts.shape)\n",
    "    # entry_character[]\n",
    "# for i in range(new_index.shape[0]):\n",
    "#     element_counts = Counter(cindex[i,:])\n",
    "#     for j in range(entry_character.shape[0]):\n",
    "#         entry_character[j,i]=element_counts[j]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "data=entry_character.cpu().numpy()\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# best_k = int(input(\"根据图形输入最佳K值: \"))  # 交互式选择\n",
    "# 或者直接指定 best_k = 8\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=16,\n",
    "                        batch_size=8192,\n",
    "                        random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# 5. 保存结果\n",
    "np.save('cluster_labels.npy', cluster_labels)\n",
    "print(\"聚类完成，标签已保存为cluster_labels.npy\")\n",
    "\n",
    "# 可选：查看聚类中心\n",
    "print(\"聚类中心形状:\", kmeans.cluster_centers_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2969,  0.8789,  0.5352,  0.4922],\n",
      "        [-0.2041, -0.7383, -0.4414,  1.6250],\n",
      "        [ 0.8359,  0.6602,  0.3691, -0.4316],\n",
      "        ...,\n",
      "        [ 1.9688,  0.6250,  1.3906,  0.6289],\n",
      "        [-1.3203, -0.3477,  1.3906, -1.3281],\n",
      "        [ 0.2480,  0.5156,  0.6992, -0.3066]], grad_fn=<IndexBackward0>) [52581 52642 14430 ... 34454 34442 65520]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "centroids = centroids.view(65536, 8).to(dev)  # 修正拼写错误并准备张量\n",
    "sorted_indices = np.argsort(cluster_labels)\n",
    "centroids = centroids[sorted_indices]\n",
    "centroids = centroids.view(16384, 32).to(device=dev, dtype=torch.float32)\n",
    "# 创建 code 张量，确保在 dev 上并为 float32\n",
    "code = torch.zeros([16384, 4], dtype=torch.float32, device=dev)\n",
    "code = centroids[:, [0, 8, 16, 24]]\n",
    "print(code,sorted_indices)\n",
    "print(cluster_labels[52581])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图中的顶点数： 65536\n",
      "图中的边数： 0\n"
     ]
    }
   ],
   "source": [
    "#图优化：\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "for i in range(65536):\n",
    "    G.add_node(i)\n",
    "\n",
    "# for i in range(65536):\n",
    "#     for j in range (65536):\n",
    "#         G.add_edge(i,j,weight=0)\n",
    "\n",
    "# for i in range(64):\n",
    "#     for j in range(64):\n",
    "#        node1=new_index[i,j].item()\n",
    "#        node2=new_index[i,j+1].item()\n",
    "#     #    print(node1,node2)\n",
    "#        if G.has_edge(node1, node2):\n",
    "#             weight=G[node1][node2]['weight']+1\n",
    "#             G.add_edge(node1,node2,weight=weight)\n",
    "#        else:\n",
    "#             G.add_edge(node1,node2,weight=1)\n",
    "print(\"图中的顶点数：\", G.number_of_nodes())\n",
    "print(\"图中的边数：\", G.number_of_edges())\n",
    "import numpy as np\n",
    "matrix = np.array([[1, 1, 3],\n",
    "                   [1, 1, 6],\n",
    "                   [7, 8, 9]])\n",
    "a=set(matrix[0])\n",
    "b=set(matrix[1])\n",
    "similarity = a.intersection(b)\n",
    "print(similarity)\n",
    "index=new_index.numpy()\n",
    "similarity_matrix = np.zeros((448, 448))\n",
    "for i in range(448):\n",
    "    for j in range(i+1, 448):\n",
    "        set_i = set(index[i]) # 第i行的唯一条目集合\n",
    "        set_j = set(index[j])  # 第j行的唯一条目集合\n",
    "        similarity = len(set_i.intersection(set_j))  # 计算共享条目数\n",
    "        similarity_matrix[i][j] = similarity\n",
    "        similarity_matrix[j][i] = similarity\n",
    "        print(i,j,similarity_matrix[i][j])\n",
    "        def find_max_weight_edge(G, node):\n",
    "    max_weight = -1\n",
    "    max_edge = None\n",
    "    for neighbor in G.neighbors(node):\n",
    "        weight = G[node][neighbor]['weight']\n",
    "        if weight > max_weight:\n",
    "            max_weight = weight\n",
    "            max_edge = (node, neighbor)\n",
    "    return max_edge, max_weight\n",
    "\n",
    "# 指定的顶点\n",
    "specified_node = 59581\n",
    "for i in range(65536) :\n",
    "    edges = G.edges(i, data=True)\n",
    "\n",
    "# 打印与节点1920相连的所有节点及其边的权重\n",
    "    print(f\"与节点 {i} 相连的所有节点及其边的权重：\")\n",
    "for edge in edges:\n",
    "    print(f\"节点 {edge[1]}，权重 {edge[2]['weight']}\")\n",
    "    # 找到与指定顶点相连的最大权重边\n",
    "    # max_edge, max_weight = find_max_weight_edge(G, i)\n",
    "\n",
    "    # if max_edge is not None:\n",
    "    #     print(f\"\\n与顶点 {i} 相连的最大权重边为：{max_edge}，权重为：{max_weight}\")\n",
    "    # else:\n",
    "    #     print(f\"\\n顶点 {i} 没有相连的边\")\n",
    "\n",
    "    import networkx as nx\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "# BFS遍历图\n",
    "def bfs_traversal(G, start_node):\n",
    "    visited = set()  # 记录已访问的节点\n",
    "    queue = deque([start_node])\n",
    "    visited.add(start_node)\n",
    "    traversal_order = []  # 记录遍历顺序\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        traversal_order.append(node)\n",
    "        for neighbor in G.neighbors(node):\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "    return traversal_order\n",
    "\n",
    "# 从节点0开始BFS遍历\n",
    "start_node = 0\n",
    "traversal_result = bfs_traversal(G, start_node)\n",
    "\n",
    "# 打印遍历结果\n",
    "print(\"\\nBFS遍历顺序（从节点 {} 开始）：\".format(start_node))\n",
    "print(traversal_result)\n",
    "\n",
    "# 如果图不连通，遍历未访问的节点\n",
    "if len(traversal_result) < len(G.nodes()):\n",
    "    print(\"\\n图不连通，继续遍历其他未访问的节点：\")\n",
    "    all_nodes = set(G.nodes())\n",
    "    remaining_nodes = all_nodes - set(traversal_result)\n",
    "    for node in remaining_nodes:\n",
    "        if node not in visited:\n",
    "            sub_traversal = bfs_traversal(G, node)\n",
    "            traversal_result.extend(sub_traversal)\n",
    "            print(\"从节点 {} 开始的遍历结果：{}\".format(node, sub_traversal))\n",
    "\n",
    "print(\"\\n完整的BFS遍历顺序：\")\n",
    "print(traversal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "值为14750的元素出现的位置: [(1, 2149), (1, 2281), (1, 2594), (1, 2868), (2, 3526), (9, 2415)]\n",
      "值为25986的元素出现的位置: [(4, 2420), (5, 1044), (5, 1131), (5, 1189), (5, 1446), (12, 3434), (45, 785)]\n",
      "值为7921的元素出现的位置: [(12, 36), (12, 295), (12, 1093), (12, 3064), (17, 495), (24, 156), (38, 403)]\n",
      "值为19530的元素出现的位置: [(13, 1035), (13, 1942), (13, 1969), (13, 2046), (28, 2491), (37, 2673), (50, 2723)]\n",
      "值为11093的元素出现的位置: [(9, 2402), (14, 2026), (16, 651), (16, 726), (16, 1049), (16, 2407), (46, 3370), (55, 2355)]\n",
      "值为60442的元素出现的位置: [(17, 77), (17, 1018), (17, 3390), (17, 3516)]\n",
      "值为64199的元素出现的位置: [(18, 245), (18, 290), (18, 381), (18, 1328), (22, 3371), (23, 2143), (52, 2870)]\n",
      "值为23780的元素出现的位置: [(19, 870), (19, 2339), (19, 3101), (19, 3351)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "值为18962的元素出现的位置: [(21, 860), (21, 871), (21, 1625), (21, 1749), (25, 28), (30, 3235)]\n",
      "值为18929的元素出现的位置: [(1, 1492), (8, 3035), (12, 1745), (24, 210), (24, 1695), (24, 2041), (24, 3582)]\n",
      "值为47425的元素出现的位置: [(21, 632), (25, 3083), (27, 3084), (28, 487), (28, 625), (28, 880), (28, 1937)]\n",
      "值为10341的元素出现的位置: [(32, 327), (32, 781), (32, 1294), (32, 1354), (32, 2890), (32, 3233), (33, 2079)]\n",
      "值为62270的元素出现的位置: [(33, 52), (33, 1907), (33, 1908), (33, 2736), (48, 2503)]\n",
      "值为18288的元素出现的位置: [(35, 685), (35, 2155), (35, 2378), (35, 2645), (35, 3472)]\n",
      "值为58413的元素出现的位置: [(10, 1111), (34, 3082), (36, 252), (36, 1671), (36, 2234), (36, 2984), (40, 1627), (42, 2578)]\n",
      "值为35490的元素出现的位置: [(37, 339), (37, 1840), (37, 2279), (37, 2992), (47, 930), (50, 3177)]\n",
      "值为65428的元素出现的位置: [(36, 2046), (39, 496), (39, 604), (39, 833), (39, 1361)]\n",
      "值为30957的元素出现的位置: [(0, 2042), (5, 817), (8, 3392), (40, 636), (40, 848), (40, 1126), (40, 1684), (40, 2487)]\n",
      "值为6047的元素出现的位置: [(32, 1952), (32, 2902), (39, 1015), (41, 164), (41, 1283), (41, 2481), (41, 2566), (42, 1410)]\n",
      "值为27615的元素出现的位置: [(11, 55), (42, 82), (42, 1897), (42, 1979), (42, 2164), (44, 1870)]\n",
      "值为57795的元素出现的位置: [(25, 3363), (28, 3473), (46, 438), (46, 1701), (46, 1758), (46, 2074), (46, 3108), (58, 3551)]\n",
      "值为13468的元素出现的位置: [(46, 2225), (47, 29), (47, 497), (47, 2795), (47, 3163)]\n",
      "值为9352的元素出现的位置: [(40, 898), (40, 1549), (51, 0), (51, 3), (51, 5), (51, 8), (59, 16), (63, 3306)]\n",
      "值为21554的元素出现的位置: [(41, 2253), (43, 2306), (53, 0), (53, 1), (53, 2), (53, 3), (55, 6), (59, 11)]\n",
      "值为10315的元素出现的位置: [(54, 1884), (54, 2104), (54, 2580), (54, 3133)]\n",
      "值为55140的元素出现的位置: [(32, 1853), (34, 1842), (42, 1182), (55, 1), (55, 2), (55, 3), (55, 4)]\n",
      "值为23139的元素出现的位置: [(11, 2756), (25, 2989), (49, 439), (55, 1595), (61, 662), (61, 1421), (61, 2341), (61, 2632)]\n",
      "值为46252的元素出现的位置: [(10, 17), (32, 1909), (34, 411), (40, 1962), (42, 314), (43, 634), (63, 9), (63, 11), (63, 13), (63, 14)]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "cindex=new_index.cpu().numpy()\n",
    "# element_counts = Counter(cindex[7,:])\n",
    "# print(element_counts) # 输出: Counter({3: 3, 1: 2, 2: 2})\n",
    "# element_counts = Counter(cindex[8,:])\n",
    "# print(element_counts) # 输出: Counter({3: 3, 1: 2, 2: 2})\n",
    "# centroids = centroids.view(65536, 8).to(dev)  # 修正拼写错误并准备张量\n",
    "for i in range(64):\n",
    "    element_counts = Counter(cindex[i,:])\n",
    "    elements = []\n",
    "    frequencies = []\n",
    "    print(element_counts)\n",
    "    # for element, count in element_counts.most_common():\n",
    "    #     elements.append(element)\n",
    "    #     frequencies.append(count)\n",
    "    # if frequencies[0]>=4:\n",
    "        # print(element_counts)\n",
    "        # positions = []\n",
    "        # for i, row in enumerate(cindex):\n",
    "        #     for j, value in enumerate(row):\n",
    "        #         if value == elements[0]:\n",
    "        #             positions.append((i, j))\n",
    "        #             # print(cindex[i,j+1])\n",
    "        # print(f\"值为{elements[0]}的元素出现的位置:\", positions)\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = []\n",
    "for i, row in enumerate(cindex):\n",
    "   for j, value in enumerate(row):\n",
    "       if value == elements[2]:\n",
    "           positions.append((i, j))\n",
    "print(f\"值为{elements[2]}的元素出现的位置:\", positions)\n",
    "\n",
    "# x=range()\n",
    "# # 创建图像\n",
    "# plt.figure(figsize=(10, 6))  # 设置图像大小\n",
    "\n",
    "# # 绘制折线图\n",
    "# plt.plot(x, y, label='sin(x)', color='b', linewidth=2)\n",
    "\n",
    "# # 添加标题和标签\n",
    "# plt.title('1D Plot of sin(x)', fontsize=16)\n",
    "# plt.xlabel('X-axis', fontsize=14)\n",
    "# plt.ylabel('Y-axis', fontsize=14)\n",
    "\n",
    "# # 添加图例\n",
    "# plt.legend()\n",
    "\n",
    "# # 添加网格\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# # 显示图像\n",
    "# plt.show()\n",
    "# # # 输出结果\n",
    "# print(\"值为60391的元素出现的位置:\", positions)\n",
    "        # for j in range(10):\n",
    "        #     centroids[[elements[0]+j+1,elements[j+1]]]=centroids[[elements[j+1],elements[0]+j+1]]\n",
    "\n",
    "\n",
    "# centroids = centroids.view(16384, 32).to(device=dev, dtype=torch.float32)\n",
    "# # 创建 code 张量，确保在 dev 上并为 float32\n",
    "# code = torch.zeros([16384, 4], dtype=torch.float32, device=dev)\n",
    "# code = centroids[:, [0, 8, 16, 24]]\n",
    "\n",
    "# centroids = centroids.view(65536, 8).to(dev)  # 修正拼写错误并准备张量\n",
    "# centroids[[46680,36823]]=centroids[[36823,46680]]\n",
    "# centroids[[46681,56983]]=centroids[[56983,46681]]\n",
    "# centroids[[46682,63703]]=centroids[[63703,46682]]\n",
    "# centroids[[46683,26519]]=centroids[[26519,46683]]\n",
    "# centroids[[46352,53967]]=centroids[[53967,46352]]\n",
    "# centroids = centroids.view(16384, 32).to(device=dev, dtype=torch.float32)\n",
    "# # 创建 code 张量，确保在 dev 上并为 float32\n",
    "# code = torch.zeros([16384, 4], dtype=torch.float32, device=dev)\n",
    "# code = centroids[:, [0, 8, 16, 24]]\n",
    "# positions = []\n",
    "# for i, row in enumerate(cindex):\n",
    "#     for j, value in enumerate(row):\n",
    "#         if value == 63839:\n",
    "#             positions.append((i, j))\n",
    "\n",
    "# # 输出结果\n",
    "# print(\"值为60391的元素出现的位置:\", positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict, defaultdict\n",
    "from collections import deque, defaultdict\n",
    "class cache_sim:\n",
    "    def __init__(self, mode, linesize, cachesize, num_lin, codebook):\n",
    "        self.linesize = linesize\n",
    "        self.num_lin = num_lin\n",
    "        self.cache = torch.full((num_lin, linesize), -1)\n",
    "        self.codebook = codebook\n",
    "        \n",
    "        # 预建 codebook 值到行的快速映射 (值 -> 行索引)\n",
    "        self.codebook_value_map = {}\n",
    "        for row_idx, row in enumerate(codebook):\n",
    "            for val in row:\n",
    "                val = val.item()\n",
    "                if val not in self.codebook_value_map:\n",
    "                    self.codebook_value_map[val] = row_idx\n",
    "        \n",
    "        # 使用 OrderedDict 实现高效 LRU 机制\n",
    "        self.lru = OrderedDict()\n",
    "        \n",
    "        # 值到缓存行的反向映射 (值 -> 所在行集合)\n",
    "        self.value_to_lines = defaultdict(set)\n",
    "        # 缓存行到值的反向映射 (行 -> 存储的值集合)\n",
    "        self.line_to_values = [set() for _ in range(num_lin)]\n",
    "\n",
    "    def maintain_record(self, line):\n",
    "        \"\"\" 更新 LRU 记录，O(1) 时间复杂度 \"\"\"\n",
    "        if line in self.lru:\n",
    "            self.lru.move_to_end(line)\n",
    "        else:\n",
    "            self.lru[line] = None\n",
    "\n",
    "    def is_empty(self):\n",
    "        \"\"\" 返回可替换的行或 -1 \"\"\"\n",
    "        if len(self.lru) < self.num_lin:\n",
    "            return -1\n",
    "        else:\n",
    "            # 弹出 LRU 行并清理其反向映射\n",
    "            lru_line, _ = self.lru.popitem(last=False)\n",
    "            for val in self.line_to_values[lru_line]:\n",
    "                self.value_to_lines[val].remove(lru_line)\n",
    "                if not self.value_to_lines[val]:\n",
    "                    del self.value_to_lines[val]\n",
    "            self.line_to_values[lru_line].clear()\n",
    "            return lru_line\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\" 加载数据到缓存，向量化操作 \"\"\"\n",
    "        data_val = data.item()\n",
    "        if data_val not in self.codebook_value_map:\n",
    "            raise ValueError(f\"Value {data_val} not in codebook\")\n",
    "        \n",
    "        code_row = self.codebook[self.codebook_value_map[data_val]]\n",
    "        target_line = self.is_empty()\n",
    "        \n",
    "        if target_line == -1:\n",
    "            # 寻找未使用的行\n",
    "            for line in range(self.num_lin):\n",
    "                if line not in self.lru:\n",
    "                    target_line = line\n",
    "                    break\n",
    "            # 如果所有行已使用，触发 LRU 替换\n",
    "            if target_line == -1:\n",
    "                target_line = self.is_empty()\n",
    "        # print(target_line)\n",
    "        # 更新缓存行数据\n",
    "        self.cache[target_line] = code_row\n",
    "        # 更新反向映射\n",
    "        new_values = set(code_row.tolist())\n",
    "        for val in new_values:\n",
    "            self.value_to_lines[val].add(target_line)\n",
    "        self.line_to_values[target_line] = new_values\n",
    "        self.maintain_record(target_line)\n",
    "\n",
    "    def sim(self, read_data):\n",
    "        \"\"\" 批量查询优化，O(1) 时间复杂度 \"\"\"\n",
    "        data_val = read_data.item()\n",
    "        \n",
    "        # \n",
    "        if data_val in self.value_to_lines:\n",
    "            # 取第一个关联行并更新 LRU\n",
    "            line = next(iter(self.value_to_lines[data_val]))\n",
    "            self.maintain_record(line)\n",
    "            return True\n",
    "        else:\n",
    "            self.load_data(read_data)\n",
    "            # print('not hit')\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.603347\n",
      "Hit Rate: 0.998895\n"
     ]
    }
   ],
   "source": [
    "def run_simulation(code,recon_weight):\n",
    "    # 将输入数据转换为向量化操作\n",
    "    cache_l1=cache_sim(mode=None, linesize=4, cachesize=None, num_lin=256, codebook=code)\n",
    "    cache_l2=cache_sim(mode=None, linesize=4, cachesize=None, num_lin=2048, codebook=code)\n",
    "    recon_flatten = recon_weight.reshape(-1) #按行解码\n",
    "    hit_cnt = torch.sum(torch.tensor([\n",
    "        cache_l1.sim(val) for val in recon_flatten\n",
    "    ], dtype=torch.int32))\n",
    "    hit_cnt=hit_cnt.item()\n",
    "    sum_cnt=len(recon_flatten)\n",
    "    print(f\"Hit Rate: {hit_cnt / sum_cnt:.6f}\")\n",
    "    hit_cnt = torch.sum(torch.tensor([\n",
    "        cache_l2.sim(val) for val in recon_flatten\n",
    "    ], dtype=torch.int32))\n",
    "    hit_cnt=hit_cnt.item()\n",
    "    sum_cnt=len(recon_flatten)\n",
    "    print(f\"Hit Rate: {hit_cnt / sum_cnt:.6f}\")\n",
    "    return None\n",
    "run_simulation(code,recon_weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
