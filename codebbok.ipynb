{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded VPTQ CUDA kernels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Replacing linear layers...: 100%|██████████| 399/399 [00:00<00:00, 3622.63it/s]\n",
      "/home/jzgrp/xiaomenghan/anaconda3/envs/pytorch310/lib/python3.10/site-packages/accelerate/utils/modeling.py:1517: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(152064, 3584)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          (q_proj): VQuantLinear(\n",
      "            (centroids): Embedding(1, 524288)\n",
      "          )\n",
      "          (k_proj): VQuantLinear(\n",
      "            (centroids): Embedding(1, 524288)\n",
      "          )\n",
      "          (v_proj): VQuantLinear(\n",
      "            (centroids): Embedding(1, 524288)\n",
      "          )\n",
      "          (o_proj): VQuantLinear(\n",
      "            (centroids): Embedding(1, 524288)\n",
      "          )\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): VQuantLinear(\n",
      "            (centroids): Embedding(1, 524288)\n",
      "          )\n",
      "          (up_proj): VQuantLinear(\n",
      "            (centroids): Embedding(1, 524288)\n",
      "          )\n",
      "          (down_proj): VQuantLinear(\n",
      "            (centroids): Embedding(1, 524288)\n",
      "          )\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import os,sys\n",
    "import vptq\n",
    "import transformers\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "model_name = \"VPTQ-community/Qwen2.5-7B-Instruct-v8-k65536-0-woft\"  # 替换为你需要的模型名称\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, legacy=True)\n",
    "model = vptq.AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,  # 使用半精度加速推理\n",
    "        trust_remote_code=True,\n",
    ").eval()\n",
    "\n",
    "prompt=\"hello\"\n",
    "out = model.generate(\n",
    "    **tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\"),\n",
    "    max_new_tokens=100,\n",
    "    pad_token_id=2\n",
    ")\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "path=\"/home/jzgrp/xiaomenghan/vptq_qwen2-7/model.layers.0.self_attn.q_proj_indices.pt\"\n",
    "matrix = torch.load(path)  # 若文件在GPU上，需先转到CPU: matrix = torch.load('matrix.pt').cpu()\n",
    "q_centroids=model.model.layers[0].self_attn.q_proj.centroids\n",
    "q_cen_weight=q_centroids.weight.view(1,65536,8)\n",
    "# 2. 转换为NumPy数组\n",
    "# np_matrix = matrix.cpu().numpy()\n",
    "np_matrix=q_cen_weight.cpu().detach().numpy()\n",
    "# 3. 检查维度并调整（假设需要二维）\n",
    "print(\"矩阵形状:\", np_matrix.shape)\n",
    "if np_matrix.ndim > 2:\n",
    "    # 示例：如果维度是3D（如通道x高度x宽度），取第一个通道\n",
    "    np_matrix = np_matrix[0][0:512]\n",
    "elif np_matrix.ndim == 1:\n",
    "    raise ValueError(\"矩阵是一维的，无法直接可视化。\")\n",
    "\n",
    "# 4. 使用热图可视化\n",
    "plt.figure(figsize=(8, 32))\n",
    "plt.imshow(np_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='indices')\n",
    "plt.title(\"Indices data distribution\")\n",
    "plt.xlabel(\"column index\")\n",
    "plt.ylabel(\"row index\")\n",
    "\n",
    "# 5. 保存图片\n",
    "plt.savefig('indices_data.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_centroids=model.model.layers[0].self_attn.q_proj.centroids\n",
    "q_cen_weight=q_centroids.weight.view(1,65536,8)\n",
    "print(q_cen_weight.shape)\n",
    "print(matrix.shape,matrix.dtype)\n",
    "a=matrix[0,0,0]\n",
    "# a=a&0x0000ffff\n",
    "print(a)\n",
    "a=torch.bitwise_and(a, 0xFFFF).to(torch.uint16)\n",
    "print(a)\n",
    "print(q_cen_weight[0,a,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_mask=0xffff0000\n",
    "low_mask=0x0000ffff\n",
    "new_index=torch.zeros([448,3584])\n",
    "for j in range(matrix.shape[1]):\n",
    "    for k in range(matrix.shape[2]):\n",
    "        packint32=matrix[0,j,k].to(torch.int32)\n",
    "        new_index[j,2*k+1]=torch.bitwise_right_shift(packint32.to(torch.int64),16).to(torch.uint16)\n",
    "        new_index[j,2*k]=torch.bitwise_and(packint32, 0xFFFF).to(torch.uint16)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_vector=torch.zeros([5,448,8])\n",
    "for i in range(channel_vector.shape[0]):\n",
    "    for j in range(channel_vector.shape[1]):\n",
    "        index=new_index[j,i].to(torch.uint16)\n",
    "        channel_vector[i,j,:]=q_cen_weight[0,index,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1, figsize=(8, 32))\n",
    "channel_vector=channel_vector.cpu().detach().numpy()\n",
    "for i in range(5):\n",
    "    # 绘制每个子图\n",
    "    im = axs[i].imshow(channel_vector[i,:,:], cmap='viridis', interpolation='nearest')\n",
    "    axs[i].set_title(f\"Indices data distribution {i+1}\")\n",
    "    axs[i].set_xlabel(\"column index\")\n",
    "    axs[i].set_ylabel(\"row index\")\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = fig.colorbar(im, ax=axs[i], orientation='vertical', pad=0.05, aspect=40)\n",
    "    cbar.set_label('indices')\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
